\section{Evaluation}
\label{sec:evaluation}

In this section we evaluate \textit{Jorvik} in three different ways. 
In the first evaluation, we apply \textit{Jorvik} to generate a Papyrus editor for the non-trivial Archimate UML profile~\cite{iacob2009archimate,haren2012archimate}. 
We use the Adocus Archimate for Papyrus\footnote{\url{https://github.com/Adocus/ArchiMate-for-Papyrus}} (an open-source tool that includes a profile for Archimate and the appropriate editors for Papyrus) for reference. 
We compare the proportion of the tool that \textit{Jorvik} is able to generate automatically, check the number of polishing transformations that the user needs to write to complete the missing parts and finally, identify the aspects of the editor that our approach is not able to generate.
As a result we can measure the \textit{efficiency} of \textit{Jorvik} in generating profiles/editors against an existing relatively large profile/editor. 

In the second evaluation, we assess the \textit{completeness} of \textit{Jorvik} by applying it to a number of metamodels collected as part of the work presented in~\cite{williams2013metamodels}. 
This way, \textit{Jorvik} is tested to check if it can successfully generate profiles and editors for a wide variety of scenarios.

In the third evaluation, we conduct a \textit{user experiment} in which we asked software engineers to build Papyrus editors for two UML Profiles.
We first ask the engineers to create the profiles and editors manually, and then ask them to create the same profiles and editors using \textit{Jorvik}. 
We measure the time, report problems encountered during the experiment for both approaches and we compare the results.

\subsection{Efficiency}
\label{sec:efficiencyEvaluation}
The Archimate for Papyrus tool offers five kinds of diagrams (i.e., Application, Business, Implementation and Migration, Motivation and Technology diagrams). 
Each of the diagrams uses different stereotypes from the Archimate profile. 
In this scenario, we create five Ecore metamodels and annotate the elements that need to appear as nodes/edges in the diagrams. 
We then generate the editors for all the five Archimate diagrams.
At this point, five fully functional editors are generated that can be used to create each of the five types of diagrams that the Archimate for Papyrus tool also supports. 

However, our generated editors do not offer some special features that the Archimate for Papyrus tool offers. 
For example, Archimate for Papyrus offers a third drawer in the palette for some diagrams that is called ``Common'' and includes two tools (named ``Grouping'' and ``Comment''). 
Another feature that is not supported by our default transformations is the fact that in Archimate for Papyrus, users are able to have the elements represented either by their shapes or by a coloured rectangle depending on the CSS class applied to them. 
Finally, Archimate for Papyrus also organises the creation of the \textit{Junction} (which is a node that acts as a junction for edges) node in the relations' drawer in the palette.
In order to be able to implement such missing features, we need to write the extra polishing transformations. 
We do not go into details on the content of the polishing transformations for this specific example\footnote{The generated Plug-ins for Archimate and the polishing transformations are available from \url{https://github.com/wrwei/Jorvik}}.

In our previous work \cite{zolotas2018towards}, we compared our approach with Archimate for Papyrus. 
However, as we mentioned in Section~\ref{sec:background}, Papyrus changed its underlying metamodels and the mechanism for creating UML specific editors. 
To ensure that our results are still valid for Papyrus 3.0+, we re-generated all the Archimate editors using \textit{Jorvik}. 
We add the lines of code needed for \textit{Jorvik} to our findings in the previous work.

Table~\ref{tab:evaluation} summarises the efficiency of \textit{Jorvik}, both for \textit{Jorvik} pre-Papyrus 3.0 version and for \textit{Jorvik} post-Papyrus 3.0 version\footnote{Cells in gray are artefacts not needed for implementation. E.g. Creation Command and Architecture Model are concepts in Papyrus version 3.0+, and therefore are not applicable to \textit{Jorvik} pre-Papyrus 3.0 version and Archimate for Papyrus}. The numbers are shown in the format of \textit{Lines of Code (Number of Model Elements)}, as we count both the lines of code and (equivalent) number of model elements needed to be created manually. For artefacts which are not models (e.g., the CSS file) we only provide the lines of code metric as well for artefacts created by polishing transformations in \textit{Jorvik}, as these were generated by the polishing transformation scripts.

For \textit{Jorvik} pre-Papyrus 3.0 (columns under \textit{Jorvik (pre-Papyrus 3.0)}), we need to manually create five annotated Ecore metamodels, which involves writing 436 lines of code (668 model elements). 
For polishing transformations, we need to write 11 lines of code in the transfornation script for Element Types Configuration, 50 lines for Palette Configuration, 195 lines for CSS and 10 lines for Types Configuration.
For \textit{Jorvik} post-Papyrus 3.0 (columns under \textit{Jorvik (post-Papyrus 3.0)}), we need the same Ecore metamodels (i.e., five), thus the numbers do not change. 
For polishing transformations, we need to write 50 lines for the Palette Configuration and 195 lines for CSS. 

As it can be observed from the numbers, our approach requires about 90\% less handwritten code to produce the basic diagrams and about 85\% less code to 
produce the polished editor that matches the original Archimate for Papyrus editor. 
%The produced by Jorvik editors match those included in the original Archimate for Papyrus tool.
Our approach creates the five diagram editors which offer the same functionality and features as the original Archimate for Papyrus tool but also atop that the ETL transformation and the OCL constraints.

\subsubsection{Threats to Validity}
There were a few minor features of the original Archimate for Papyrus tool that our approach could not support. 
Most of them are related to custom menu entries and wizards. For those to be created developer needs to extend the ``plugin.xml'' file. 
In addition, the line decoration shapes of stereotypes that extend the aggregation base element (i.e., diamond) can only be applied dynamically by running Java code that will update the property each time the stereotype is applied. 
Our default and polishing transformations are not able to generate those features automatically; these should be implemented manually. 
For that reason, we \textit{excluded} these lines of code needed by Archimate for Papyrus to implement these features from the data provided in Table~\ref{tab:evaluation} for a fair comparison. 


\captionsetup{justification=centering}
\begin{landscape}
	\topskip0pt
	%	\vspace*{\fill}
	\begin{table}
		\centering
		\setlength{\tabcolsep}{3.5pt} 
		\begin{tabular}{M{1.5cm}|M{1.8cm}|M{1.8cm}|M{1.8cm}|M{1.8cm}|M{1.8cm}|M{1.8cm}|M{3cm}|}
			\cline{2-8}
			& \multicolumn{3}{M{5.4cm}|}{\textbf{Jorvik (pre-Papyrus 3.0)} LoC~(Number of Model Elements)} & \multicolumn{3}{M{5.1cm}|}{\textbf{Jorvik (post-Papyrus 3.0)}  LoC~(Number of Model Elements)} & \textbf{Archimate for Papyrus (Pre Papyrus 3.0)}\\ \hline
			\multicolumn{1}{|M{2cm}|}{\textbf{File}} & \textbf{Hand-written} & \textbf{Hand-written (Polishing)} & \textbf{Total} & \textbf{Hand-written} & \textbf{Hand-written (Polishing)} & \textbf{Total} & \textbf{Total Hand-written}\\ \hline
			\multicolumn{1}{|M{2cm}|}{\textbf{Ecore}} & 436 (668) & 0 & 436 (668) & 436 (668) & 0 & 436 (668) & 0 \\ \hline
			\multicolumn{1}{|M{2cm}|}{\textbf{Profile}} & 0 & 0 & 0 & 0 & 0 & 0 & 1867 (1089) \\ \hline
			\multicolumn{1}{|M{2cm}|}{\textbf{Element Types Configuration}} & 0 & 11 & 11 & 0 & 0 & 0 & 237 (61) \\ \hline
			\multicolumn{1}{|M{2cm}|}{\textbf{Palette Configuration}} & 0 & 50 & 50 & 0 & 50  & 50  & 1305 (323) \\ \hline
			\multicolumn{1}{|M{2cm}|}{\textbf{CSS}} & 0 & 195 & 195 & 0 & 195 & 195 & 537 \\ \hline
			\multicolumn{1}{|M{2cm}|}{\textbf{Creation Command}} & \cellcolor{Gray} & \cellcolor{Gray} & \cellcolor{Gray} & 0 & 0 & 0 & \cellcolor{Gray}  \\ \hline
			\multicolumn{1}{|M{2cm}|}{\textbf{Architecture Model}} & \cellcolor{Gray} & \cellcolor{Gray}& \cellcolor{Gray} & 0 & 0 & 0 & \cellcolor{Gray}  \\ \hline
			\multicolumn{1}{|M{2cm}|}{\textbf{Types Configuration}} & 0 & 10 & 10 & \cellcolor{Gray} & \cellcolor{Gray}& \cellcolor{Gray} & 788 (327) \\ \hline
			\multicolumn{1}{|M{2cm}|}{\textbf{Diagram Configuration}} & 0 & 0 & 0 & \cellcolor{Gray} & \cellcolor{Gray}& \cellcolor{Gray} & 58 (28) \\ \hline
			%\multicolumn{1}{|M{2cm}|}{\textbf{plugin.xml}} & 0 & & & 82 \\ \hline
			%\multicolumn{1}{|M{2cm}|}{\textbf{MANIFEST.MF}} & 0 & & & \\ \hline
			\multicolumn{1}{|M{2cm}|}{\textbf{Total}}  & \textbf{436 (668)} &\textbf{266} & \textbf{702 (668)} & \textbf{436 (668)} & \textbf{245} & \textbf{681 (668)} & \textbf{4792 (1828)} \\ \hline
			\cline{1-8}
		\end{tabular}
		\caption{Lines of manually written code of each file for creating a Papyrus UML profile and editor for ArchiMate.}
		\label{tab:evaluation}
	\end{table}
\end{landscape}






\subsection{Completeness}
\label{sec:completenessEvaluation}
In addition to the generation of the Archimate profile/editors, we test \textit{Jorvik} with nine more Ecore metamodels from different domains. 
The names of the metamodels (including Archimate) and their size (in terms of types) are provided in Table~\ref{tab:metamodels}. 
Next to the size, in parenthesis, the number of types that should be transformed so they can be instantiated as nodes/edges is also provided.

As illustrated in Table~\ref{tab:metamodels}, the metamodels vary in size, from small profiles (with 5 stereotypes) to large profiles (with up to 57 
stereotypes). 
The approach is able to produce the profiles and the editors for \textit{all} metamodels, demonstrating that it can be used to generate the 
desired artifacts for a wide spectrum of domains. 
The time needed for the generation varies from miliseconds up to a few seconds. 
In the future, we plan to assess further the scalability of our approach using larger metamodels.

\begin{table}[htb!]
	\centering
	\setlength{\tabcolsep}{3.5pt} 
	\caption{The names and sizes of the ten metamodels against which the approach was evaluated to test completeness}	\begin{tabular}{|c|M{3cm}|c|M{3cm}|}
		\cline{1-4}
		\textbf{Name}  & \textbf{\#Types (\#Nodes/\#Edges)} & \textbf{Name}  & \textbf{\#Types (\#Nodes/\#Edges)}\\ \hline
		\textbf{Professor} & 5 (4/5)  & \textbf{Ant Scripts} & 11 (6/4) \\ \hline
		\textbf{Zoo} & 8 (6/4) & \textbf{Cobol} & 13 (12/14) \\ \hline
		\textbf{Usecase} & 9 (4/4) & \textbf{Wordpress} & 20 (19/18)  \\ \hline
		\textbf{Conference} & 9 (7/6) & \textbf{BibTeX} & 21 (16/2) \\ \hline
		\textbf{Bugzilla} & 9 (7/6) & \textbf{Archimate} & 57 (44/11) \\ \hline
		\cline{1-4}
	\end{tabular}

	\label{tab:metamodels}
\end{table}


\subsection{User Experiment}
We have argued that \textit{Jorvik} provides significant gains in productivity when building custom UML Profile editors for Papyrus.
We design a user experiment to substantiate our claim and quantify the productivity improvement. 
As discussed in Section~\ref{sec:implementation}, there are eight major steps to be taken in order to create a UML profile as well as its supporting editor. 
In this experiment, we compare the time needed to develop an editor using Papyrus infrastructure (hereby referred to as the \textit{Papyrus approach}) with the time needed to develop the same editor using \textit{Jorvik}.
For the Papyrus approach we design eight tasks, each with its own deadline (see Table~\ref{tab:manual}) for the participants to complete towards manually creating a UML profile and a working UML editor for the profile.
For \textit{Jorvik}, we design one task for the participants to complete to automatically generate a UML profile and a working UML editor for that profile.
We ask two participants to take part in the experiment and work on two profiles we choose. 
We record the time taken for the participants to complete the experiment using both approaches and we compare the times.

\subsubsection{Papyrus Approach Experiment Set-Up}
For the purpose of this experiment, we have chosen a participant with relatively more experience in modelling, and a candidate with less experience in modelling. 
Both participants have an Eclipse IDE installed on their computers, with Eclipse Epsilon 1.6 Interim version\footnote{\url{https://www.eclipse.org/epsilon/}} and Eclipse Papyrus 4.0.0\footnote{\url{https://www.eclipse.org/papyrus/download.html}} installed.
We ask the participants to perform the tasks involved in the Papyrus approach firstly on one profile (the Website profile\footnote{\url{https://github.com/wrwei/Jorvik/tree/master/org.papyrus.website}}) and then repeat the experiment for a second profile (the Fault Tree profile\footnote{\url{https://github.com/wrwei/Jorvik/tree/master/org.papyrus.faulttree}}) following again the Papyrus approach. 
The SVG shapes and icons for both cases are provided to the participants. 
Before the experiment is conducted, a pre-experiment questionnaire is handed to the participants, to assess their expertise in UML, UML profiles and Papyrus\footnote{The questions can be viewed in \url{https://github.com/wrwei/Jorvik/wiki/Pre-Experiment-Self-Assessment-Questionnaire}}. 
In addition, a 20-30 minutes introduction to UML profiles and Papyrus is given to them while an example of a custom UML profile Papyrus editor is being presented to them. 

For each of the eight steps, there is a set deadline; the participants are asked to try to complete the step within the deadline.
The tasks and the deadlines are derived from our own experience in developing an UML profile and its distributable Papyrus editor. 
Initially we spent 3 months on creating an example editor, due to the lack of documentation and the lack of tool support when referencing model elements among the models required for the editor.
After we found out how to create an editor, we recorded the amount of time required for us to perform the eight steps to derive the deadlines. 
We then normalise the deadlines through a pilot study with a volunteer from our research group (we also make adjustments to our experiment set-up in the pilot study based on what we learnt from it). 

In each step, the participants are asked to complete a minimal task first (e.g., for UML profile, create a stereotype that is displayed as a node and a stereotype that is displayed as an edge)\footnote{Detailed descriptions of the tasks can be found at \url{https://github.com/wrwei/Jorvik/tree/master/User_Experiment}}. 
They are asked to continue with the rest if there is still time left. 
If the participants miss the deadline but they are working towards the correct solution, they are asked to give an estimate of how long they believe it would take them to finish the whole step.
At the beginning of each step, we provide a piece of \textit{Default} knowledge, which covers ground knowledge for the step to be completed. 
Participants are also allowed to search for any information over the Internet which may assist them in their tasks at any point during the experiment.
At a certain point for each step, we assess if the participants are able to complete the step within the time frame, and we provide a piece of \textit{Essential} knowledge, which contains key information (which is not easily accessible from the Internet) for the participants to complete the step.

\begin{table}
	\centering
	\setlength{\tabcolsep}{3.5pt} 
	\caption{Tasks and times (in minutes) for the Papyrus approach.}
	\begin{tabular}{|c|c|c|c|}
		\cline{1-4}
		\textbf{Task} & Total (m) & Default (m) & Essential (m) \\ \hline
		1. UML Profile & 60 & 40 & 20 \\ \hline
		2. Element Types Configuration Model & 60 & 40 & 20 \\ \hline
		3. Palette Configuration Model & 30 & 20 & 10 \\ \hline
		4. Cascading Style Sheet & 30 & 20 & 10 \\ \hline
		5. Creation Command & 30 & 20 & 10 \\ \hline
		6. Architecture Model & 40 & 30 & 10 \\ \hline
		7. Plug-in Configuration & 20 & 12 & 8 \\ \hline
		8. OCL Constraints & 60 & 40 & 20 \\ \hline
	\end{tabular}
	\label{tab:manual}
\end{table}


Table~\ref{tab:manual} lists an overview of the tasks. It also includes the times (in minutes) for the total time given (i.e., Total (m))  and the deadlines (in minutes) for the task with the default (i.e., Default (m)) and the essential (i.e., Essential (m)) knowledge.
The task descriptions are as follows:
\begin{enumerate}
	\item UML Profile - An image of a UML profile is provided to the participants, they are required to create the profile within 60 minutes.
	\textit{Essential} information is provided at minute 40.
	\item Element Types Configuration Model - Participants are asked to create an Element Types Configuration model for the editor for the profile they created in task 1.
	\item Palette Configuration Model - Participants are asked to create a Palette Configuration model for the editor/profile.
	\item Custom Style - Participants are asked to create a CSS file to customise the styles of the editor.
	\item Creation Command - Participants are asked to create the creation command Java class to initialise the Papyrus diagram .
	\item Architecture Model - Participants are asked to create an Architecture model for the editor/profile.
	\item Plug-in Configuration - Participants are asked to configure their plug-ins in order to make use of all the models/artefacts to form a working editor
	\item OCL constraints (optional) - In this optional task, participants are asked to create OCL constraints mentioned in Section~\ref{sec:constraints} for all connector stereotypes, within 60 minutes. 
	We do not expect this task to be taken by participants, as it typically required experienced OCL experts 2 weeks to complete the constraint templates described in Section~\ref{sec:constraints}.
	For the record, no participants agreed to take this optional task.
\end{enumerate}

For each step, when participants express that they have completed the step, we stop the timer and assess the solutions. 
If the solutions are not correct, we tell the participants that they need more work and resume the timer. 

Since each step depends on the previous being completed, at the beginning of each step, the participants are given a solution that contains complete and correct assets for all the previous tasks.

After participants have completed the manual process, a post-experiment questionnaire is handed to them, in which they evaluate the difficulties of each task and if enough time was provided for each task\footnote{The questions can be viewed in \url{https://github.com/wrwei/Jorvik/wiki/Post-Experiment-Self-Assessment-Questionnaire}}.

\begin{table}[ht!]
	\centering
	\setlength{\tabcolsep}{3.5pt} 
	\caption{Task and time (in minutes) for the \textit{Jorvik} approach.}
	\begin{tabular}{|c|c|c|c|}
		\cline{1-4}
		\textbf{Task} & Total (m) & Default (m) & Essential (m) \\ 
		1. Ecore Metamodel and Generation & 50 & 30 & 20 \\ \hline
	\end{tabular}
	\label{tab:automatic}
\end{table}

\subsubsection{\textit{Jorvik} Experiment Set-up}
The experiment then proceeds to the use of \textit{Jorvik}, where the participants need to complete one task (see Table~\ref{tab:automatic}):
\textbf{Annotated Ecore Metamodel and Generation} - Participants are provided with the same images of the profiles (one each time), they are asked to create an annotated Ecore metamodel for the profile, and generate the UML profile and the editor, within 50 minutes.
	The \textit{Default} information is provided at the beginning. 
	30 minutes in the task, we assess the participants' status and provide the \textit{Essential} information.

\input{resultsTable.tex}

\subsubsection{Results}
Table~\ref{tab:experiment} shows the times obtained from the user experiment.
Participant \#1 is a female PhD student who has a high level of expertise in modelling, and has used Papyrus before.
Participant \#2 is a male PhD student who has an intermediate level of expertise in modelling, and has used Papyrus on a limited number of occasions. 
Both of the participants have no experience in creating distributable editors for UML profiles using Papyrus.

In the table, the \textit{Task} column specifies the name of the steps. 
The \textit{Time Given} column specifies the time we gave the participants for each step having the \textit{Default} knowledge only and in parenthesis the time we gave to them having the \textit{Essential} knowledge information.
The \textit{Time Taken} column records the time taken for the participants to complete the Website profile (\textit{Web}) and the Fault Tree profile (\textit{FTA}). Times with an \textit{asterisk (*)} denote that the participant asked and was given the essential information\footnote{In some tasks participants knew how to complete the task with no more information given to them, but they hit the deafult knowledge deadline. In such cases we were assessing the solution and if it was indeed towards the correct direction they were allowed to use the time remaining to complete the task without giving the essential information.}.
The \textit{Correctness} column records if the participants are able to provide correct, partial correct (e.g. participants miss some style properties in the CSS file) and incorrect solutions. 
The participants are distinguished using the \textit{Participant} column.
We record any comments/remarks made by the participants in the \textit{Remarks} column (se discuss the remarks made by the participants later in this section).
%Note: the time it takes for Jorvik to generate Papyrus editors based on Ecore metamodels is negligible, therefore is not included in the results.


Below is an example of how the table should be read (the summary of the experiment for Participant \#1 for the Papyrus approach for the Website profile):
\begin{enumerate}
	\item She was able to finish the UML profile creation in 25 minutes without the \textit{Essential} knowledge. 
	\item She finished the Element Types Configuration in 56 minutes with the help of the \textit{Essential} knowledge. 
	
%	\textit{Remark \textcircled{1}:} She claimed that she found a solution online.\footnote{Which is the forum thread where the authors obtained the correct way of creatin Element Types Configurations: \url{https://www.eclipse.org/forums/index.php/t/1096471/}}.
	\item She finished the tasks in Step 3 in 26 minutes with the help of the \textit{Essential} knowledge.
	
%	\textit{Remark \textcircled{3}:} She claims that she would need 20 more minutes to finish the model.
	\item She finished a partial solution for the CSS in 15 minutes.
	\item She could not figure out how to create a creation command, therefore \textit{Essential} knowledge is provided, and she finished the step in 25 minutes in total.
	
%	\textit{Remark \textcircled{5}:} She copied the actual solution for the essential information given.
	\item She could not figure out how to create an Architecture model, even with the \textit{Essential} knowledge provided and missed the deadline.
	\item She was not able to configure the editor Plug-in to successfully run the editor, even with the \textit{Essential} knowledge. 
	
%	\textit{Remark \textcircled{8}: } She claims that she would need 30+ minutes more to finish the configuration.
\end{enumerate}

%In total Participant \#1 spent 208 minutes 30 seconds on the manual process for the Website profile.
%
%Below is the summary for Participant \#1 using the Papyrus approach for the Fault Tree profile:
%
%\begin{itemize}
%	\item She was able to finish the UML profile creation in 15 minutes without the essential information. 
%	\item She finished the Element Types Configuration in 38 minutes without the help of the essential information.
%	\item She finished the Palette Configuration model in 25 minutes without the help of the essential information.
%	\item She finished a complete solution for the CSS in 16 minutes.
%	\item She finished the creation command Java class in 16 minutes.
%	\item She finished the architecture model in 25 minutes.
%	\item She was able to configure the editor plug-in to successfully run the editor in 10 minutes.
%\end{itemize}
%\thanos{I think that we need to make a remark here that in many tasks she copy-paste part of the solution from the Website profile and adapted it}
%In total Participant \#1 spent 140 minutes using the Papyrus approach for the Fault Tree profile.\thanos{Again participant \#1, right?}
%
%Below is the summary for Participant \#2 for the Papyrus approach for the Website profile:
%\begin{enumerate}
%	\item He was able to finish the UML profile creation in 40 minutes without the essential information. 
%	\item He could not finish the Element Types Configuration model, even with the help of the essential knowledge. 
%	\item He could not figure out how to complete the Palette Configuration model, even with the essential knowledge. 
%	\item He finished a partial solution for the CSS in 30 minutes.
%	\item He could not figure out how to create a creation command, therefore essential information is provided, and he finished the step in 30 minutes in total.
%	\item He could not figure out how to create an Architecture model, even with the essential information provided and he still missed the deadline. 
%	
%	\textit{Remark \textcircled{6}:} He estimated that he would need 60+ minutes more to finish the model.
%	\item He was able to configure the editor plug-in to successfully run the editor in 19 minutes.
%\end{enumerate}
%In total Participant \#2 spent 249 minutes seconds using the Papyrus approach for the Website profile.
%
%Below is the summary for Participant \#2 for the Papyrus approach for the Fault Tree Profile:
%
%\begin{enumerate}
%	\item He was able to finish the UML profile creation in 24 minutes without the essential information. 
%	\item He finished the minimal task for the Element Types Configuration in 58 minutes with the help of the essential information. 
%	
%	\textit{Remark: \textcircled{2}} He would need 40+ minutes to complete the whole model.
%	\item He finished the Palette configuration model in 22 minutes with the help of essential however the solution was not correct.
%	
%	\textit{Remark \textcircled{4}:} \thanos{Text is missing for this remark.}.
%	\item He finished a complete solution for the CSS in 19 minutes.
%	\item He finished the creation command Java class in 25 minutes.
%	\item He finished the architecture model in 32 minutes with the help of the essential knowledge. 
%	
%	\textit{Remarks: \textcircled{7}: The solution was incorrect.}
%	\item She was able to configure the editor plug-in to successfully run the editor in 10 minutes.
%\end{enumerate}
%In total Participant \#2 spent 206 minutes using the Papyrus approach for the Fault Tree profile.

We also note some remarks made by the participants during the experiment.
Below is a list of the description of the remarks in the table, which should be read together with the experiment results:
\begin{itemize}
	\item Remark \textcircled{1}: In the Website experiment, in Step 2, Participant \#1 claimed that she found a solution online\footnote{Which is the forum thread where the authors obtained the correct way of creating Element Types Configurations: \url{https://www.eclipse.org/forums/index.php/t/1096471/}.} that made the task significantly easier. 
	She also claims that without the solution there is no way she could have finished the task, even with the \textit{Essential} knowledge.
	\item Remark: \textcircled{2} In both the Website and the Fault Tree experiment, in Step 2, Participant \#2 claimed that he could never complete the step, without the essential information. 
	He also claims that the Element Types Configuration is rather confusing.
	In the Fault Tree experiment, he claimed he would need 40+ minutes to complete the whole model.
	\item Remark \textcircled{3}: In the Website experiment, in Step 3, Participant  \#1 finished the minimal task with the help of the essential information. She	claimed that she would need 20 more minutes to finish the model.
	\item Remark \textcircled{4}: In the Website experiment, in Step 3, Participant  \#2 missed the deadline even with the essential information.
	He claimed that he would need 30 more minutes to finish the step.
	\item Remark \textcircled{5}: In the Website experiment (and presumably in the Fault Tree experiment), in step 5, participant  \#1 claims that she copied the actual solution for the essential information given.
	\item Remark \textcircled{6}: In the Website experiment, in step 6, participant  \#1 missed the deadline even with the essential information. 
	She claims that the tool support for the Architecture model by Papyrus is not well implemented (it does not support the reference to model elements in other models).
	\item Remark \textcircled{7}: Participant  \#2 in both rounds of this experiment claimed that he finished the step before the deadline (both with the help of the essential information), but he could not get the solutions correct. 
	This is typically due to the fact that there are somewhat confusing model elements in the Architecture metamodel by Papyrus.
	\item Remark \textcircled{8}: In the Website experiment, in step 7, Participant  \#1 could not configure the plug-in to a working order, she claimed that she would need more than 20 minutes to inspect other models to find out what went wrong.
\end{itemize}
For the results obtained using \textit{Jorvik}, participant \#1 was able to generate the correct Papyrus editor for the Website profile in 32 minutes. She was also able to create the correct editor for the Fault Tree profile in 15 minutes.
Participant \#2 needed 37 minutes and 38 minutes for the creation of a correct Papyrus editor for the Website and the Fault Tree profiles, respectively, using \textit{Jorvik}.


\subsubsection{Analysis} 
We begin our analysis with usefull insights from the responses to the pre and post-experiment questionnaires.
From the pre-experiment questionnaires\footnote{Available at \url{https://github.com/wrwei/Jorvik/blob/master/User_Experiment/Pre-Experiment_Self_Assessment_Responses.pdf}}, we found out that both participants had intermediate knowledge of UML but have not created a UML profile in the past using any tool (including Papyrus).

By analysing the responses to the post-experiment questionnaires\footnote{Available at \url{https://github.com/wrwei/Jorvik/blob/master/User_Experiment/Post_Experiment_Self_Assessment_Responses.pdf}} for the Papyrus approach,
both participants felt that the time assigned to the tasks, most of the times, were not enough for the first round of the experiment (the Website experiment). However, they felt the time was enough for the second round of the experiment (the Fault Tree experiment). This is because participants were able to refer to their Website solution in the second round. Both participants mentioned it was difficult to find the documentation needed to finish the steps (\textit{NB}: this applies only to responses after the first experiment as they mostly referred to the editor produced in that one when executing the second).

For all the steps in the Papyrus approach, except the one in which participants had to create the UML profile, they declared that they had low to moderate confidence that they will be able to complete the task before receiving the essential information. This is can be explained from the lack of experience in developing UML profile editors with Papyrus before. For the same steps (i.e., 2-7), participant 2 highlighted 
that he felt completely lost before receiving the \textit{Essential} information. However, both of them declared to have moderate to high confidence after receiving the \textit{Essential} information, except for step 2, where both were still confused by the concept of Element Types Configuration. This confirms our findings as this task is the one that participants performed worse (see Table~\ref{tab:experiment}). 
	
To summarise, from the responses received, step 2 (Element Types Configuration), step 3 (Palette Configuration), Step 5 (Creation Command) and step 6 (Architecture Model) were identified as typical obstacles for the participants in completing the whole experiments. 

Regarding the questionnaires from the \textit{Jorvik} experiment, participant \#1 described herself as knowledgable of EMF, had created EMF metamodels in the past, and had also used annotations. 
Participant \#2 had no EMF experience in the past and had never created an EMF metamodel. Finally, both mentioned that the time given was enough and that they felt more confident after receiving the essential information.

By analysing the results provided in Table~\ref{tab:experiment}, comparing the Papyrus approach with \textit{Jorvik}, we can conclude that using \textit{Jorvik} users are able to increase the productivity by at least 10 times (especially when participants claim that they would need additional time to finish the complete solution for some steps). This is also due to the fact that both participants chose not to complete the optional Step 8 (the OCL constraints), which may take significant time, even for experienced OCL programmers.

We are also able to draw the conclusion that it is rather difficult to derive the models/artefacts needed for a working UML profile-specific editor. 
This is based on the experiment results that both participants got the majority of their models/artefacts wrong for the Website profile, which was the first profile and editor they worked on.
Although we provided the \textit{Essential} information, parts of which, to the best of our knowledge, are not available in Papyrus documentation, participants still could not get the models/artefacts right because of the inter-related nature of the models.
For example, both participants find it difficult to comprehend the purpose of the Element Types Configuration, they actually find that it is the most challenging part of the experiment.
The candidates also find it difficult to link creation tools in the Palette Configuration model to elements in the Element Types Configuration. 
They also find it hard to understand the rationale behind referencing to Element Types Configuration.
Finally, both participants claimed that it is rather difficult to create the Architecture model, as there are concepts defined in it which purposes are not orthogonal to their experience.
%This provides evidence that creating a distributable UML profile editor in Papyrus is a labour-intensive and error-prone process.
In addition, due to the inter-connected nature among the models/artefacts, participants find it difficult to debug their solutions, as there are many places where things may go wrong.
In contrast, \textit{Jorvik} provides feedback based on the validation rules applied to the annotated Ecore metamodel, which helped participants in debugging.
In practice, during the \textit{Jorvik} experiment, we noticed that participants made use of the feedback provided by \textit{Jorvik} to debug their annotated Ecore metamodels.

When participants worked on the Fault Tree profile, they were able to refer to their solutions to the Website profile. 
Therefore we observe that the correctness of the models/artefacts for the Fault Tree profile improved significantly comparing to the Website profile. This matches our experience with using the Papyrus infrastructure for the development of distributable editors for UML profiles, where we had to reverse engineer other editors available online to try to understand how to proceed.
Although they may have adapted their Website solutions to their Fault Tree solution, the recorded time shows that \textit{Jorvik} still performs significantly better than the manual process, especially taking the OCL constraints into consideration.

It is worth mentioning that Participant \#1 is an expert user of Ecore, where Participant \#2 only used Ecore from the training provided prior to the experiment. 
We observe the advantage of being familiar with Ecore based on Participant \#1's time taken for the experiments (especially after she got familiar with the annotation rules for \textit{Jorvik}).
However, for both levels of expertise in Ecore, the experiment suggests that the time taken is still significantly better using \textit{Jorvik} compared to the Papyrus approach.

\subsubsection{Threats to Validity}
For the experiment we used participants that do not specialise in creating UML profiles and their supporting editors for Papyrus. The time taken if our participants were Papyrus experts might be lower.
%This is typically due to the fact that this feature of Papyrus is not widely promoted and adopted.
However, as we have spent significant time working with Papyrus and \textit{Jorvik}, we have run the experiment ourselves for both the profiles and we monitored the same time benefits (about 10 times faster using \textit{Jorvik}). 
%In fact we recorded the time it took us to finish the whole solution and derived the deadlines for each step in the Papyrus approach based on the our own times and normalised the deadlines based on a pilot experiment taken by a volunteer researcher. [Thanos: we mention this already above]

In the Papyrus experiment, we take a waterfall approach.
We derived the eight steps in the Papyrus experiment based on our own experience, each step depends on previous steps. 
For example, step 2 (Element Types Configuration Model) depends on the whole solution of step 1 (the UML profile), step 3 (Palette Configuration Model) depends on step 2. 
There is one exception that step 5 (Creation Command) depends on step 7 (Plug-in Configuration) as the Creation Command Java class relies on the definition of URI mappings, required in the plug-in. 
However, this does not affect the experiment results, as when participants work on step 7, we notify them that they need to also alter their solution in step 5.

The Jorvik experiment was run in both cases after the Papyrus one. Participants might become familiar with the domain described in the metamodel after finishing the Papyrus experiment and this could reduce the time for understanding the domain in the Jorvik experiment. 

Finally, participants require the whole solution of the editor in order to test the correctness of the models/artefacts produced in each step. Both participants found that it is difficult to test the models they develop, because it requires the whole solution in order to test a single model. We do not consider this as a flaw in our experiment as it is a replicate of our own experience.
In addition, to mitigate this issue, we performed a manual review of the models/artefacts when it was requested to inspect their correctness.
